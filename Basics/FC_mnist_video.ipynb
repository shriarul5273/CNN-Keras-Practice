{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FC_mnist_video.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO76gLm13FaQsNrxH2F7yrY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shriarul5273/CNN-Keras-Practice/blob/main/Basics/FC_mnist_video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lqq8QpohaIiq"
      },
      "source": [
        "#### Key Details \n",
        "```\n",
        "    DataSet: MNIST from inbuilt in Keras\n",
        "    Deep learning Framework: Tensorflow with Keras\n",
        "    Deep learning Method: Fully Connected only\n",
        "    Optimizer:SGD with 0.01\n",
        "    Results: 96 to 98 % Accurate\n",
        "```\n",
        "#### Inspired from [Lex Fridman's github Page](https://github.com/lexfridman/mit-deep-learning)\n",
        "#### Done by shriarul643@gmail.com\n",
        "#### OutPut Video at [my github page](https://github.com/shriarul5273/CNN-Keras-Practice/blob/main/Basics/output.mp4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2yR2H94aSzv"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVJj4kIbadr3",
        "outputId": "f800a68b-5310-4b44-e0e3-1b72d522f68c"
      },
      "source": [
        "\n",
        "(trainData,trainLabel),(testData,testLabel) = mnist.load_data()\n",
        "\n",
        "print(trainData.shape)\n",
        "print(trainLabel.shape)\n",
        "print(testData.shape)\n",
        "print(testLabel.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EK3GMq1kahA5"
      },
      "source": [
        "trainData = trainData.reshape(trainData.shape[0],trainData.shape[1]*trainData.shape[2])\n",
        "testData = testData.reshape(testData.shape[0],testData.shape[1]*testData.shape[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFLOVeJKalpo",
        "outputId": "3b08d5ce-8203-4348-c553-21f70af0d53f"
      },
      "source": [
        "lb = LabelBinarizer()\n",
        "trainLabel = lb.fit_transform(trainLabel)\n",
        "testLabel = lb.fit_transform(testLabel)\n",
        "print(testData.shape)\n",
        "print(trainData.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 784)\n",
            "(60000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kriLaDCzath5"
      },
      "source": [
        "model = Sequential([Dense(500,input_shape=(trainData.shape[1],),activation='sigmoid'),\n",
        "                    Dense(256,activation='sigmoid'),\n",
        "                    Dense(128,activation='sigmoid'),\n",
        "                    Dense(10,activation='softmax')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7Eq1zBhawWg",
        "outputId": "ec602164-d2ce-4ed0-8779-89a4337c77bf"
      },
      "source": [
        "sgd = SGD(0.01)\n",
        "model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.fit(trainData,trainLabel,batch_size=128,epochs=25,validation_data=(testData,testLabel))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 2.2910 - accuracy: 0.2341 - val_loss: 2.1188 - val_accuracy: 0.5204\n",
            "Epoch 2/25\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 2.0584 - accuracy: 0.5889 - val_loss: 1.8181 - val_accuracy: 0.6594\n",
            "Epoch 3/25\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 1.7270 - accuracy: 0.6903 - val_loss: 1.4060 - val_accuracy: 0.7391\n",
            "Epoch 4/25\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 1.3232 - accuracy: 0.7420 - val_loss: 1.0656 - val_accuracy: 0.7864\n",
            "Epoch 5/25\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 1.0136 - accuracy: 0.7872 - val_loss: 0.8468 - val_accuracy: 0.8201\n",
            "Epoch 6/25\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.8182 - accuracy: 0.8268 - val_loss: 0.7011 - val_accuracy: 0.8518\n",
            "Epoch 7/25\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.6826 - accuracy: 0.8518 - val_loss: 0.5965 - val_accuracy: 0.8726\n",
            "Epoch 8/25\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.5846 - accuracy: 0.8711 - val_loss: 0.5212 - val_accuracy: 0.8852\n",
            "Epoch 9/25\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.5144 - accuracy: 0.8829 - val_loss: 0.4649 - val_accuracy: 0.8912\n",
            "Epoch 10/25\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4555 - accuracy: 0.8935 - val_loss: 0.4217 - val_accuracy: 0.8985\n",
            "Epoch 11/25\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4157 - accuracy: 0.9016 - val_loss: 0.3894 - val_accuracy: 0.9029\n",
            "Epoch 12/25\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.3835 - accuracy: 0.9075 - val_loss: 0.3624 - val_accuracy: 0.9094\n",
            "Epoch 13/25\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.3549 - accuracy: 0.9131 - val_loss: 0.3415 - val_accuracy: 0.9116\n",
            "Epoch 14/25\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.3312 - accuracy: 0.9171 - val_loss: 0.3236 - val_accuracy: 0.9147\n",
            "Epoch 15/25\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.3088 - accuracy: 0.9216 - val_loss: 0.3091 - val_accuracy: 0.9178\n",
            "Epoch 16/25\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2986 - accuracy: 0.9226 - val_loss: 0.2958 - val_accuracy: 0.9198\n",
            "Epoch 17/25\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2776 - accuracy: 0.9278 - val_loss: 0.2861 - val_accuracy: 0.9223\n",
            "Epoch 18/25\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2691 - accuracy: 0.9296 - val_loss: 0.2760 - val_accuracy: 0.9244\n",
            "Epoch 19/25\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2556 - accuracy: 0.9337 - val_loss: 0.2664 - val_accuracy: 0.9259\n",
            "Epoch 20/25\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2472 - accuracy: 0.9355 - val_loss: 0.2587 - val_accuracy: 0.9294\n",
            "Epoch 21/25\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.2327 - accuracy: 0.9376 - val_loss: 0.2531 - val_accuracy: 0.9304\n",
            "Epoch 22/25\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2284 - accuracy: 0.9400 - val_loss: 0.2450 - val_accuracy: 0.9317\n",
            "Epoch 23/25\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2157 - accuracy: 0.9449 - val_loss: 0.2397 - val_accuracy: 0.9335\n",
            "Epoch 24/25\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.2095 - accuracy: 0.9445 - val_loss: 0.2345 - val_accuracy: 0.9355\n",
            "Epoch 25/25\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.2018 - accuracy: 0.9475 - val_loss: 0.2297 - val_accuracy: 0.9346\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7336a0a5c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUKLpxFoazwI"
      },
      "source": [
        "cap = cv2.VideoCapture('mnist_dream.mp4')\n",
        "codec = cv2.VideoWriter_fourcc(*'DIVX')\n",
        "vw = cv2.VideoWriter('output.mp4', codec, 30, (1080,1080))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLkrpONAbXyj"
      },
      "source": [
        "while cap.isOpened():\n",
        "    ret,frame = cap.read()\n",
        "    if ret == True:\n",
        "        testImageGray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
        "        testImage = 255-cv2.resize(testImageGray,(28,28))\n",
        "        testImage = testImage.reshape(1,784)\n",
        "        predict = model.predict(testImage)\n",
        "        j = np.argmax(predict[0])\n",
        "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "        line_style = cv2.LINE_AA\n",
        "        image = np.zeros((720, 720, 3), dtype='uint8')\n",
        "        H, W = image.shape[:2]\n",
        "        x, y = 50, 150\n",
        "        for i,p in enumerate(predict[0]):\n",
        "            text = '{}:  {:.2f}%'.format(i, p*100)\n",
        "            if i == j:\n",
        "                color = (255,0,0)\n",
        "            else:\n",
        "                color = (255,255,255)\n",
        "            cv2.rectangle(image, (x + 200, y + i * 60), (x + 200 + int(p*800), y + i * 60 + 25), color, -1)\n",
        "            cv2.putText(image, text, (x, y + i * 60 + 25), font, 1, color, 2, lineType=line_style)\n",
        "        outputImage = 255-cv2.resize(frame,(720,720),interpolation=cv2.INTER_AREA)\n",
        "        outputImage = np.hstack([outputImage,image])\n",
        "        text = \"Input:\"\n",
        "        cv2.putText(outputImage, text, (50, 40), font, 1, (255, 255, 255), 2, lineType=line_style)\n",
        "        text = \"Neural Network Output:\"\n",
        "        cv2.putText(outputImage, text, (750, 40), font, 1, (255, 255, 255), 2, lineType=line_style)\n",
        "        outputImage = cv2.resize(outputImage,(1080,1080),)\n",
        "        vw.write(outputImage)\n",
        "        vw.write(outputImage)\n",
        "    else:\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "vw.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_MIhC1jbcyY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}